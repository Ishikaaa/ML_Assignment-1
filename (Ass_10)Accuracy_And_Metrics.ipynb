{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(Ass-10)Accuracy_And_Metrics.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ishikaaa/Machine-Learning-Assignments/blob/master/(Ass_10)Accuracy_And_Metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "vMM6pIPYYiaM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# ***1. Import The Dataset - ***"
      ]
    },
    {
      "metadata": {
        "id": "ON7QFuVNW-ZE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "from sklearn.datasets import load_digits "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ta-YsSJvaeod",
        "colab_type": "code",
        "outputId": "8109ed64-8364-41b1-d9ab-a89d33486bab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1040
        }
      },
      "cell_type": "code",
      "source": [
        "load_digits()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttp://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\",\n",
              " 'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
              "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
              "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
              "        ...,\n",
              "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
              "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
              "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
              " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
              "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
              "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
              "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
              "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
              "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
              "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
              "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
              "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
              "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
              "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
              "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
              "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
              "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
              "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
              "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
              "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
              "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
              "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
              "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
              "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
              " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
              " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "Jk-KMjFbatFP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# ***2. Save X(features) and y(target) as dataframes -***"
      ]
    },
    {
      "metadata": {
        "id": "G8k2KVDBYwJn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X=pd.DataFrame(load_digits().data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QVEAKOxqY7Ks",
        "colab_type": "code",
        "outputId": "513b57fc-cd1c-4cf9-e2db-74bd2353e610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 64 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    0    1    2     3     4     5    6    7    8    9  ...    54   55   56  \\\n",
              "0  0.0  0.0  5.0  13.0   9.0   1.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
              "1  0.0  0.0  0.0  12.0  13.0   5.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
              "2  0.0  0.0  0.0   4.0  15.0  12.0  0.0  0.0  0.0  0.0 ...   5.0  0.0  0.0   \n",
              "3  0.0  0.0  7.0  15.0  13.0   1.0  0.0  0.0  0.0  8.0 ...   9.0  0.0  0.0   \n",
              "4  0.0  0.0  0.0   1.0  11.0   0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
              "\n",
              "    57   58    59    60    61   62   63  \n",
              "0  0.0  6.0  13.0  10.0   0.0  0.0  0.0  \n",
              "1  0.0  0.0  11.0  16.0  10.0  0.0  0.0  \n",
              "2  0.0  0.0   3.0  11.0  16.0  9.0  0.0  \n",
              "3  0.0  7.0  13.0  13.0   9.0  0.0  0.0  \n",
              "4  0.0  0.0   2.0  16.0   4.0  0.0  0.0  \n",
              "\n",
              "[5 rows x 64 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "hjlaOAi2ZVyG",
        "colab_type": "code",
        "outputId": "42a6f7f0-fc8a-4f18-cdc0-f99fa44b08b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "Y=pd.DataFrame(load_digits().target)\n",
        "Y.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0\n",
              "0  0\n",
              "1  1\n",
              "2  2\n",
              "3  3\n",
              "4  4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "p6U49MpkaJSj",
        "colab_type": "code",
        "outputId": "04d220aa-9c0a-4334-9782-542bf33e7af5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Shape of X:\",X.shape)\n",
        "print(\"Shape of Y:\",Y.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X: (1797, 64)\n",
            "Shape of Y: (1797, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1ObcJUdsa5H-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# ***3. Split dataset into training and testing set - ***"
      ]
    },
    {
      "metadata": {
        "id": "hBFKULHya-FL",
        "colab_type": "code",
        "outputId": "0979b53b-6247-4ed7-97a9-3fdf890e2f83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6511
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.25,random_state=0)\n",
        "X_train,X_test,Y_train,Y_test"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(       0    1     2     3     4     5     6    7    8     9   ...     54   55  \\\n",
              " 372   0.0  3.0  13.0  16.0   9.0   0.0   0.0  0.0  0.0  10.0  ...    9.0  1.0   \n",
              " 1443  0.0  0.0   1.0  14.0  13.0   4.0   0.0  0.0  0.0   3.0  ...    6.0  0.0   \n",
              " 1792  0.0  0.0   4.0  10.0  13.0   6.0   0.0  0.0  0.0   1.0  ...    4.0  0.0   \n",
              " 211   0.0  0.0   8.0  16.0  13.0   0.0   0.0  0.0  0.0   0.0  ...    0.0  0.0   \n",
              " 632   0.0  0.0   1.0  13.0   7.0   0.0   0.0  0.0  0.0   1.0  ...    4.0  2.0   \n",
              " 818   0.0  0.0   4.0  10.0  11.0   4.0   0.0  0.0  0.0   1.0  ...    0.0  0.0   \n",
              " 427   0.0  0.0   0.0   5.0  14.0   0.0   0.0  0.0  0.0   0.0  ...    0.0  0.0   \n",
              " 1146  0.0  0.0   8.0  15.0   9.0   0.0   0.0  0.0  0.0   1.0  ...    4.0  0.0   \n",
              " 1558  0.0  0.0   3.0  11.0  13.0  15.0   3.0  0.0  0.0   4.0  ...    0.0  0.0   \n",
              " 1337  0.0  0.0  10.0  16.0  16.0  10.0   0.0  0.0  0.0   4.0  ...    8.0  0.0   \n",
              " 1191  0.0  0.0   2.0  14.0  14.0   0.0   0.0  0.0  0.0   0.0  ...   16.0  6.0   \n",
              " 501   0.0  1.0  11.0  12.0   1.0   0.0   0.0  0.0  0.0   8.0  ...   10.0  0.0   \n",
              " 937   0.0  1.0  10.0  12.0  12.0  11.0   0.0  0.0  0.0   7.0  ...   12.0  0.0   \n",
              " 553   0.0  0.0   3.0  10.0  15.0  14.0   4.0  0.0  0.0   2.0  ...    0.0  0.0   \n",
              " 1647  0.0  0.0   1.0  13.0  16.0   2.0   0.0  0.0  0.0   0.0  ...    1.0  0.0   \n",
              " 1672  0.0  0.0   9.0  15.0  16.0  15.0   2.0  0.0  0.0   4.0  ...    0.0  0.0   \n",
              " 96    0.0  1.0   9.0  16.0  15.0  10.0   0.0  0.0  0.0   6.0  ...    0.0  0.0   \n",
              " 1565  0.0  0.0   2.0  12.0  10.0   0.0   0.0  0.0  0.0   0.0  ...   16.0  4.0   \n",
              " 178   0.0  0.0   6.0  15.0  15.0   3.0   0.0  0.0  0.0   3.0  ...    9.0  0.0   \n",
              " 108   0.0  0.0   2.0  11.0  16.0   4.0   0.0  0.0  0.0   0.0  ...    0.0  0.0   \n",
              " 923   0.0  0.0   7.0  13.0  11.0   1.0   0.0  0.0  0.0   6.0  ...    8.0  0.0   \n",
              " 831   0.0  0.0   7.0  15.0  14.0   8.0   0.0  0.0  0.0   1.0  ...    0.0  0.0   \n",
              " 1361  0.0  0.0   4.0   9.0  13.0  13.0   0.0  0.0  0.0   1.0  ...    1.0  0.0   \n",
              " 1537  0.0  0.0   1.0   8.0  15.0  11.0   3.0  0.0  0.0   0.0  ...    3.0  0.0   \n",
              " 733   0.0  0.0   0.0   2.0  14.0   2.0   0.0  0.0  0.0   0.0  ...    0.0  0.0   \n",
              " 1     0.0  0.0   0.0  12.0  13.0   5.0   0.0  0.0  0.0   0.0  ...    0.0  0.0   \n",
              " 997   0.0  0.0   3.0  11.0  16.0  15.0   0.0  0.0  0.0   0.0  ...    4.0  0.0   \n",
              " 481   0.0  0.0   0.0   6.0  14.0   8.0   0.0  0.0  0.0   0.0  ...    9.0  0.0   \n",
              " 1311  0.0  0.0   0.0   1.0  16.0   3.0   0.0  0.0  0.0   0.0  ...    0.0  0.0   \n",
              " 1513  0.0  0.0   5.0  12.0  13.0   3.0   0.0  0.0  0.0   4.0  ...   11.0  0.0   \n",
              " ...   ...  ...   ...   ...   ...   ...   ...  ...  ...   ...  ...    ...  ...   \n",
              " 777   0.0  0.0   4.0  14.0  11.0   0.0   0.0  0.0  0.0   0.0  ...    0.0  0.0   \n",
              " 72    0.0  0.0   1.0  13.0  10.0   0.0   0.0  0.0  0.0   7.0  ...    0.0  0.0   \n",
              " 845   0.0  0.0   1.0   7.0  13.0  10.0   0.0  0.0  0.0   2.0  ...    8.0  0.0   \n",
              " 537   0.0  0.0   8.0  14.0   1.0   0.0   0.0  0.0  0.0   0.0  ...   12.0  4.0   \n",
              " 1701  0.0  0.0   4.0  14.0   5.0   0.0   0.0  0.0  0.0   0.0  ...   11.0  0.0   \n",
              " 849   0.0  0.0   7.0  13.0   4.0   1.0   0.0  0.0  0.0   1.0  ...    1.0  0.0   \n",
              " 1624  0.0  1.0  11.0  16.0  16.0  12.0   0.0  0.0  0.0   8.0  ...    0.0  0.0   \n",
              " 174   0.0  0.0   1.0   8.0  10.0  15.0  11.0  0.0  0.0   2.0  ...    0.0  0.0   \n",
              " 87    0.0  0.0   0.0   9.0  16.0   4.0   0.0  0.0  0.0   1.0  ...    0.0  0.0   \n",
              " 551   0.0  0.0   8.0  12.0  16.0  16.0   4.0  0.0  0.0   0.0  ...    0.0  0.0   \n",
              " 1510  0.0  0.0   0.0  12.0  10.0   0.0   0.0  0.0  0.0   0.0  ...   12.0  0.0   \n",
              " 705   0.0  0.0   6.0  14.0  16.0  16.0   2.0  0.0  0.0   5.0  ...    6.0  0.0   \n",
              " 314   0.0  0.0   3.0  12.0   3.0   0.0   0.0  0.0  0.0   0.0  ...   12.0  0.0   \n",
              " 1420  0.0  1.0  12.0  12.0  12.0  15.0   6.0  0.0  0.0   1.0  ...    0.0  0.0   \n",
              " 600   0.0  0.0  10.0  15.0   2.0   0.0   0.0  0.0  0.0   7.0  ...    8.0  3.0   \n",
              " 1496  0.0  0.0   2.0  13.0  16.0   9.0   0.0  0.0  0.0   0.0  ...    0.0  0.0   \n",
              " 1094  0.0  0.0   0.0  13.0  13.0   0.0   0.0  0.0  0.0   0.0  ...   16.0  6.0   \n",
              " 599   0.0  0.0   1.0   7.0  12.0   3.0   0.0  0.0  0.0   4.0  ...   14.0  5.0   \n",
              " 1778  0.0  0.0   0.0   1.0  13.0   8.0   0.0  0.0  0.0   0.0  ...    0.0  0.0   \n",
              " 277   0.0  0.0   0.0   4.0  13.0  13.0   0.0  0.0  0.0   0.0  ...    0.0  0.0   \n",
              " 1747  0.0  0.0   4.0  12.0  12.0   7.0   0.0  0.0  0.0   0.0  ...    0.0  0.0   \n",
              " 1033  0.0  0.0   0.0   8.0  14.0   0.0   0.0  0.0  0.0   0.0  ...    0.0  0.0   \n",
              " 1383  0.0  0.0   6.0  12.0  13.0   7.0   0.0  0.0  0.0   0.0  ...    0.0  0.0   \n",
              " 1731  0.0  0.0   0.0   2.0  14.0   0.0   0.0  0.0  0.0   0.0  ...    0.0  0.0   \n",
              " 763   0.0  0.0   8.0  14.0  16.0  16.0   1.0  0.0  0.0   6.0  ...    0.0  0.0   \n",
              " 835   0.0  1.0   8.0  14.0  15.0   2.0   0.0  0.0  0.0   2.0  ...    1.0  0.0   \n",
              " 1216  0.0  2.0   9.0  15.0  16.0  15.0   2.0  0.0  0.0  11.0  ...    7.0  0.0   \n",
              " 1653  0.0  0.0   5.0  14.0  14.0   2.0   0.0  0.0  0.0   2.0  ...    0.0  0.0   \n",
              " 559   0.0  0.0   4.0  10.0  15.0  16.0   4.0  0.0  0.0   0.0  ...    0.0  0.0   \n",
              " 684   0.0  0.0   6.0  14.0  13.0   4.0   0.0  0.0  0.0   4.0  ...    1.0  0.0   \n",
              " \n",
              "        56   57    58    59    60    61    62    63  \n",
              " 372   0.0  2.0  16.0  16.0  14.0  12.0   9.0   1.0  \n",
              " 1443  0.0  0.0   0.0   9.0  14.0  13.0   1.0   0.0  \n",
              " 1792  0.0  0.0   2.0  14.0  15.0   9.0   0.0   0.0  \n",
              " 211   0.0  0.0  12.0   9.0   0.0   0.0   0.0   0.0  \n",
              " 632   0.0  0.0   1.0  15.0  16.0  15.0  13.0  15.0  \n",
              " 818   0.0  0.0   5.0  12.0  12.0  12.0   1.0   0.0  \n",
              " 427   0.0  0.0   0.0   7.0  12.0   0.0   0.0   0.0  \n",
              " 1146  0.0  0.0   9.0  13.0  12.0  10.0   1.0   0.0  \n",
              " 1558  0.0  0.0   2.0  12.0  14.0   3.0   0.0   0.0  \n",
              " 1337  0.0  0.0  13.0  15.0  11.0   8.0  14.0   7.0  \n",
              " 1191  0.0  0.0   2.0  13.0  14.0  16.0  12.0   1.0  \n",
              " 501   0.0  0.0  13.0  11.0   8.0  12.0   8.0   0.0  \n",
              " 937   0.0  0.0  10.0  16.0  16.0  14.0   4.0   0.0  \n",
              " 553   0.0  0.0   4.0  11.0  16.0  15.0   0.0   0.0  \n",
              " 1647  0.0  0.0   1.0  11.0  16.0   8.0   0.0   0.0  \n",
              " 1672  0.0  0.0  11.0  12.0   7.0   1.0   0.0   0.0  \n",
              " 96    0.0  0.0  11.0  16.0   8.0   0.0   0.0   0.0  \n",
              " 1565  0.0  0.0   4.0  15.0   0.0   0.0   5.0   4.0  \n",
              " 178   0.0  0.0   5.0  14.0  15.0  10.0   1.0   0.0  \n",
              " 108   0.0  0.0   0.0  12.0   7.0   0.0   0.0   0.0  \n",
              " 923   0.0  0.0   7.0  16.0  16.0   9.0   1.0   0.0  \n",
              " 831   0.0  0.0   8.0  15.0  15.0   2.0   0.0   0.0  \n",
              " 1361  0.0  0.0   3.0  12.0  14.0   8.0   0.0   0.0  \n",
              " 1537  0.0  0.0   0.0  11.0  15.0   8.0   0.0   0.0  \n",
              " 733   0.0  0.0   0.0   2.0  14.0   0.0   0.0   0.0  \n",
              " 1     0.0  0.0   0.0  11.0  16.0  10.0   0.0   0.0  \n",
              " 997   0.0  0.0   3.0  15.0  16.0   9.0   0.0   0.0  \n",
              " 481   0.0  0.0   0.0   8.0  14.0  16.0   9.0   0.0  \n",
              " 1311  0.0  1.0   2.0   1.0  14.0   1.0   0.0   0.0  \n",
              " 1513  0.0  0.0   6.0  16.0  16.0  14.0   2.0   0.0  \n",
              " ...   ...  ...   ...   ...   ...   ...   ...   ...  \n",
              " 777   0.0  0.0   5.0  16.0  14.0   1.0   0.0   0.0  \n",
              " 72    0.0  0.0   1.0  15.0  14.0   8.0   0.0   0.0  \n",
              " 845   0.0  0.0   0.0   7.0  15.0  16.0  10.0   0.0  \n",
              " 537   0.0  0.0   7.0  16.0  16.0  16.0  12.0   5.0  \n",
              " 1701  0.0  0.0   4.0  13.0  16.0  15.0   5.0   0.0  \n",
              " 849   0.0  0.0   6.0  13.0  16.0   5.0   0.0   0.0  \n",
              " 1624  0.0  0.0  14.0  16.0  16.0   6.0   0.0   0.0  \n",
              " 174   0.0  0.0   1.0  16.0   5.0   0.0   0.0   0.0  \n",
              " 87    0.0  0.0   0.0  11.0  13.0   0.0   0.0   0.0  \n",
              " 551   0.0  0.0   7.0  15.0  15.0   2.0   0.0   0.0  \n",
              " 1510  0.0  0.0   2.0  10.0  16.0  16.0   5.0   0.0  \n",
              " 705   0.0  0.0   7.0  16.0  16.0   8.0   0.0   0.0  \n",
              " 314   0.0  0.0   2.0  13.0  16.0  14.0   4.0   0.0  \n",
              " 1420  0.0  2.0  16.0  15.0   8.0   1.0   0.0   0.0  \n",
              " 600   0.0  0.0   8.0  16.0  16.0  16.0  16.0   9.0  \n",
              " 1496  0.0  0.0   1.0  16.0   4.0   0.0   0.0   0.0  \n",
              " 1094  0.0  0.0   1.0  13.0  16.0  16.0  15.0   1.0  \n",
              " 599   0.0  0.0   1.0   9.0  15.0  16.0  16.0   8.0  \n",
              " 1778  0.0  0.0   0.0   0.0  15.0   7.0   0.0   0.0  \n",
              " 277   0.0  0.0   0.0   4.0  14.0  12.0   0.0   0.0  \n",
              " 1747  0.0  1.0   7.0  12.0  11.0   5.0   0.0   0.0  \n",
              " 1033  0.0  0.0   0.0  11.0  14.0   0.0   0.0   0.0  \n",
              " 1383  0.0  0.0   7.0  15.0   9.0   0.0   0.0   0.0  \n",
              " 1731  0.0  0.0   0.0   4.0  10.0   0.0   0.0   0.0  \n",
              " 763   0.0  0.0  10.0  16.0   4.0   0.0   0.0   0.0  \n",
              " 835   0.0  1.0   9.0  12.0  13.0   9.0   0.0   0.0  \n",
              " 1216  0.0  0.0  12.0  16.0  15.0   9.0   1.0   0.0  \n",
              " 1653  0.0  0.0   9.0  13.0   0.0   0.0   0.0   0.0  \n",
              " 559   0.0  0.0   6.0  16.0   4.0   0.0   0.0   0.0  \n",
              " 684   0.0  0.0   5.0  16.0  16.0  11.0   0.0   0.0  \n",
              " \n",
              " [1347 rows x 64 columns],\n",
              "        0    1     2     3     4     5     6     7    8     9  ...     54   55  \\\n",
              " 1081  0.0  0.0  11.0  16.0  15.0   3.0   0.0   0.0  0.0   5.0 ...    1.0  0.0   \n",
              " 1707  0.0  1.0  15.0  14.0   2.0   0.0   0.0   0.0  0.0   6.0 ...    0.0  0.0   \n",
              " 927   0.0  2.0  13.0  16.0  10.0   0.0   0.0   0.0  0.0  12.0 ...    6.0  0.0   \n",
              " 713   0.0  0.0   9.0   7.0   0.0   0.0   0.0   0.0  0.0   0.0 ...   11.0  0.0   \n",
              " 262   0.0  0.0   3.0  13.0   6.0   0.0   0.0   0.0  0.0   0.0 ...   11.0  0.0   \n",
              " 182   0.0  0.0   5.0  16.0  12.0   2.0   0.0   0.0  0.0   0.0 ...    0.0  0.0   \n",
              " 303   0.0  0.0   0.0  10.0  13.0   0.0   0.0   0.0  0.0   0.0 ...    0.0  0.0   \n",
              " 895   0.0  0.0   2.0  10.0  13.0  12.0   3.0   0.0  0.0   0.0 ...    0.0  0.0   \n",
              " 933   0.0  0.0  10.0  14.0  10.0   1.0   0.0   0.0  0.0   4.0 ...    7.0  0.0   \n",
              " 1266  0.0  0.0  15.0  13.0  12.0  12.0   2.0   0.0  0.0   4.0 ...    0.0  0.0   \n",
              " 788   0.0  3.0  15.0  14.0   5.0   0.0   0.0   0.0  0.0  14.0 ...   15.0  0.0   \n",
              " 1410  0.0  0.0   4.0  15.0  15.0   4.0   0.0   0.0  0.0   6.0 ...    0.0  0.0   \n",
              " 1239  0.0  0.0   1.0   9.0  15.0   2.0   0.0   0.0  0.0   0.0 ...   15.0  0.0   \n",
              " 6     0.0  0.0   0.0  12.0  13.0   0.0   0.0   0.0  0.0   0.0 ...    8.0  0.0   \n",
              " 223   0.0  0.0   0.0   8.0  12.0   1.0   0.0   0.0  0.0   0.0 ...   15.0  0.0   \n",
              " 156   0.0  0.0   0.0  16.0   7.0   0.0   0.0   0.0  0.0   0.0 ...   15.0  0.0   \n",
              " 1168  0.0  0.0   0.0   0.0  13.0  12.0   0.0   0.0  0.0   0.0 ...    0.0  0.0   \n",
              " 458   0.0  0.0   3.0  14.0  10.0   1.0   0.0   0.0  0.0   2.0 ...    0.0  0.0   \n",
              " 1061  0.0  0.0   8.0  15.0  16.0  16.0   6.0   0.0  0.0   2.0 ...    0.0  0.0   \n",
              " 722   0.0  0.0   3.0  12.0  11.0   4.0   0.0   0.0  0.0   4.0 ...    8.0  0.0   \n",
              " 513   0.0  0.0   5.0  13.0  13.0   8.0   0.0   0.0  0.0   0.0 ...    4.0  0.0   \n",
              " 438   0.0  0.0   2.0  12.0  12.0  12.0   9.0   2.0  0.0   0.0 ...    0.0  0.0   \n",
              " 1015  0.0  0.0  10.0  16.0   8.0   0.0   0.0   0.0  0.0   7.0 ...   12.0  0.0   \n",
              " 1567  0.0  0.0   3.0  15.0   3.0   0.0   0.0   0.0  0.0   0.0 ...    0.0  0.0   \n",
              " 1135  0.0  0.0  11.0  16.0  12.0  12.0  16.0   7.0  0.0   3.0 ...    0.0  0.0   \n",
              " 1320  0.0  0.0   8.0  16.0  16.0   9.0   0.0   0.0  0.0   1.0 ...    0.0  0.0   \n",
              " 1661  0.0  0.0   0.0  11.0   8.0   0.0   0.0   0.0  0.0   0.0 ...    0.0  0.0   \n",
              " 934   0.0  1.0  10.0  15.0  15.0   3.0   0.0   0.0  0.0   6.0 ...   13.0  0.0   \n",
              " 1232  0.0  2.0  11.0  16.0  15.0   6.0   0.0   0.0  0.0  11.0 ...    4.0  0.0   \n",
              " 971   0.0  0.0   5.0  15.0  14.0   3.0   0.0   0.0  0.0   2.0 ...   16.0  1.0   \n",
              " ...   ...  ...   ...   ...   ...   ...   ...   ...  ...   ... ...    ...  ...   \n",
              " 726   0.0  0.0   0.0  10.0  16.0  11.0   1.0   0.0  0.0   0.0 ...    0.0  0.0   \n",
              " 399   0.0  0.0  10.0  16.0  10.0   0.0   0.0   0.0  0.0   8.0 ...    8.0  0.0   \n",
              " 764   0.0  0.0   4.0  15.0  16.0  11.0   0.0   0.0  0.0   0.0 ...    0.0  0.0   \n",
              " 1258  0.0  0.0   5.0  12.0   0.0   0.0   0.0   0.0  0.0   0.0 ...    0.0  0.0   \n",
              " 1516  0.0  0.0   4.0  12.0   5.0   0.0   0.0   0.0  0.0   0.0 ...    5.0  0.0   \n",
              " 27    0.0  0.0   0.0   8.0  14.0  14.0   2.0   0.0  0.0   0.0 ...    0.0  0.0   \n",
              " 1663  0.0  0.0   1.0  13.0  15.0   8.0   0.0   0.0  0.0   0.0 ...    0.0  0.0   \n",
              " 757   0.0  0.0   0.0  10.0   6.0   0.0  10.0  14.0  0.0   0.0 ...    0.0  0.0   \n",
              " 289   0.0  0.0   3.0   8.0   9.0   9.0   0.0   0.0  0.0   6.0 ...    8.0  0.0   \n",
              " 1186  0.0  0.0  13.0  14.0   9.0   1.0   0.0   0.0  0.0   5.0 ...    5.0  0.0   \n",
              " 519   0.0  0.0   1.0   9.0  15.0   5.0   0.0   0.0  0.0   0.0 ...   15.0  0.0   \n",
              " 1390  0.0  0.0   9.0  16.0  16.0   7.0   0.0   0.0  0.0  13.0 ...   14.0  0.0   \n",
              " 1254  0.0  0.0   0.0   6.0  16.0   6.0   0.0   0.0  0.0   0.0 ...    0.0  0.0   \n",
              " 1712  0.0  0.0   8.0  14.0  16.0  16.0  15.0   1.0  0.0   0.0 ...    0.0  0.0   \n",
              " 210   0.0  0.0   0.0   0.0   7.0  14.0   7.0   0.0  0.0   0.0 ...    0.0  0.0   \n",
              " 760   0.0  0.0   0.0   8.0  15.0   9.0   1.0   0.0  0.0   0.0 ...    0.0  0.0   \n",
              " 491   0.0  0.0   6.0  12.0  11.0   0.0   0.0   0.0  0.0   2.0 ...   12.0  0.0   \n",
              " 1197  0.0  0.0  13.0  14.0  12.0  15.0   4.0   0.0  0.0   0.0 ...    0.0  0.0   \n",
              " 1758  0.0  0.0   3.0  13.0  16.0   5.0   0.0   0.0  0.0   6.0 ...   14.0  0.0   \n",
              " 841   0.0  0.0   0.0   8.0  13.0   2.0   0.0   0.0  0.0   0.0 ...    7.0  0.0   \n",
              " 658   0.0  0.0   6.0  15.0  15.0   1.0   0.0   0.0  0.0   4.0 ...    9.0  0.0   \n",
              " 667   0.0  0.0   4.0  16.0  15.0   4.0   0.0   0.0  0.0   0.0 ...    0.0  0.0   \n",
              " 1245  0.0  0.0   0.0   7.0  12.0   0.0   0.0   0.0  0.0   0.0 ...   16.0  2.0   \n",
              " 2     0.0  0.0   0.0   4.0  15.0  12.0   0.0   0.0  0.0   0.0 ...    5.0  0.0   \n",
              " 1367  0.0  0.0   0.0   3.0  16.0   8.0   0.0   0.0  0.0   0.0 ...    0.0  0.0   \n",
              " 1523  0.0  0.0   3.0  13.0  16.0  15.0   6.0   0.0  0.0   0.0 ...    0.0  0.0   \n",
              " 1044  0.0  1.0   7.0  15.0  16.0  16.0  14.0   0.0  0.0  10.0 ...    0.0  0.0   \n",
              " 1430  0.0  0.0  11.0  10.0   8.0  12.0   1.0   0.0  0.0   0.0 ...    5.0  0.0   \n",
              " 1723  0.0  0.0   5.0  11.0  12.0   5.0   0.0   0.0  0.0   0.0 ...    0.0  0.0   \n",
              " 1262  0.0  2.0  14.0  16.0  16.0   7.0   0.0   0.0  0.0   6.0 ...    2.0  0.0   \n",
              " \n",
              "        56   57    58    59    60    61    62   63  \n",
              " 1081  0.0  0.0  13.0  13.0   8.0  13.0  16.0  8.0  \n",
              " 1707  0.0  1.0  15.0  16.0  12.0   1.0   0.0  0.0  \n",
              " 927   0.0  1.0  13.0  16.0  16.0  16.0  16.0  3.0  \n",
              " 713   0.0  0.0   7.0  14.0  16.0  12.0   1.0  0.0  \n",
              " 262   0.0  0.0   3.0  13.0  15.0   8.0   0.0  0.0  \n",
              " 182   0.0  0.0   6.0  11.0   0.0   0.0   0.0  0.0  \n",
              " 303   0.0  0.0   1.0   5.0   7.0  15.0   8.0  0.0  \n",
              " 895   0.0  0.0   2.0  12.0  16.0  14.0   0.0  0.0  \n",
              " 933   0.0  0.0  12.0  16.0  15.0   8.0   0.0  0.0  \n",
              " 1266  0.0  1.0  15.0  16.0   4.0   0.0   0.0  0.0  \n",
              " 788   0.0  3.0  16.0  16.0  16.0  15.0   5.0  0.0  \n",
              " 1410  0.0  0.0   3.0  15.0  15.0   0.0   0.0  0.0  \n",
              " 1239  0.0  0.0   0.0  10.0  14.0  14.0   2.0  0.0  \n",
              " 6     0.0  0.0   1.0   9.0  15.0  11.0   3.0  0.0  \n",
              " 223   0.0  0.0   0.0   6.0  16.0  16.0  11.0  0.0  \n",
              " 156   0.0  0.0   1.0  11.0  16.0  15.0   9.0  0.0  \n",
              " 1168  0.0  0.0   0.0   0.0  15.0  11.0   0.0  0.0  \n",
              " 458   0.0  0.0   2.0  15.0  10.0   3.0   0.0  0.0  \n",
              " 1061  0.0  0.0   9.0  16.0   8.0   0.0   0.0  0.0  \n",
              " 722   0.0  0.0   2.0  12.0  16.0  16.0   7.0  0.0  \n",
              " 513   0.0  0.0   7.0  15.0  16.0  10.0   0.0  0.0  \n",
              " 438   0.0  0.0   3.0  15.0   3.0   0.0   0.0  0.0  \n",
              " 1015  0.0  0.0   7.0  15.0  16.0  14.0   2.0  0.0  \n",
              " 1567  0.0  0.0   4.0  16.0   5.0   0.0   0.0  0.0  \n",
              " 1135  0.0  0.0  12.0  12.0   0.0   0.0   0.0  0.0  \n",
              " 1320  0.0  0.0  11.0  16.0  16.0   6.0   0.0  0.0  \n",
              " 1661  0.0  0.0   0.0  14.0   7.0   0.0   0.0  0.0  \n",
              " 934   0.0  0.0  10.0  16.0  16.0  16.0  11.0  0.0  \n",
              " 1232  0.0  2.0  15.0  16.0  16.0  16.0  16.0  1.0  \n",
              " 971   0.0  0.0   4.0  11.0  13.0  16.0  11.0  0.0  \n",
              " ...   ...  ...   ...   ...   ...   ...   ...  ...  \n",
              " 726   0.0  0.0   0.0   8.0  15.0   1.0   0.0  0.0  \n",
              " 399   0.0  1.0  15.0  16.0  13.0  10.0   1.0  0.0  \n",
              " 764   0.0  0.0   6.0  11.0   0.0   0.0   0.0  0.0  \n",
              " 1258  0.0  0.0   3.0  14.0  12.0   3.0   0.0  0.0  \n",
              " 1516  0.0  0.0   2.0  11.0  16.0  11.0   0.0  0.0  \n",
              " 27    0.0  0.0   0.0  12.0  13.0   1.0   0.0  0.0  \n",
              " 1663  0.0  0.0   1.0  12.0  11.0   4.0   0.0  0.0  \n",
              " 757   0.0  0.0   0.0  15.0   3.0   0.0   0.0  0.0  \n",
              " 289   0.0  0.0   7.0  16.0  14.0   8.0   0.0  0.0  \n",
              " 1186  0.0  0.0  10.0  16.0  16.0  12.0   0.0  0.0  \n",
              " 519   0.0  0.0   1.0  10.0  16.0  15.0  11.0  1.0  \n",
              " 1390  0.0  0.0   9.0  16.0  16.0  14.0   5.0  0.0  \n",
              " 1254  0.0  0.0   0.0   5.0  16.0   3.0   0.0  0.0  \n",
              " 1712  0.0  0.0   9.0  13.0   5.0   0.0   0.0  0.0  \n",
              " 210   0.0  0.0   0.0   0.0   8.0  15.0   0.0  0.0  \n",
              " 760   0.0  0.0   1.0   9.0  15.0   2.0   0.0  0.0  \n",
              " 491   0.0  0.0   8.0  12.0  13.0  13.0   5.0  0.0  \n",
              " 1197  0.0  1.0  10.0  16.0   8.0   0.0   0.0  0.0  \n",
              " 1758  0.0  0.0   5.0  13.0  14.0   8.0   2.0  0.0  \n",
              " 841   0.0  0.0   0.0   8.0  16.0  13.0   2.0  0.0  \n",
              " 658   0.0  0.0   8.0  16.0  12.0   5.0   0.0  0.0  \n",
              " 667   0.0  0.0   3.0  12.0  14.0  11.0   0.0  0.0  \n",
              " 1245  0.0  0.0   0.0   9.0  14.0  14.0   5.0  0.0  \n",
              " 2     0.0  0.0   0.0   3.0  11.0  16.0   9.0  0.0  \n",
              " 1367  0.0  0.0   0.0   1.0  16.0   9.0   0.0  0.0  \n",
              " 1523  0.0  0.0   4.0  16.0   7.0   0.0   0.0  0.0  \n",
              " 1044  0.0  0.0  13.0  15.0   5.0   0.0   0.0  0.0  \n",
              " 1430  0.0  0.0  14.0  16.0  14.0   7.0   0.0  0.0  \n",
              " 1723  0.0  0.0   6.0  12.0  11.0   7.0   0.0  0.0  \n",
              " 1262  0.0  1.0  14.0  16.0  16.0   6.0   0.0  0.0  \n",
              " \n",
              " [450 rows x 64 columns],\n",
              "       0\n",
              " 372   2\n",
              " 1443  8\n",
              " 1792  9\n",
              " 211   7\n",
              " 632   2\n",
              " 818   1\n",
              " 427   4\n",
              " 1146  9\n",
              " 1558  3\n",
              " 1337  2\n",
              " 1191  6\n",
              " 501   2\n",
              " 937   5\n",
              " 553   9\n",
              " 1647  6\n",
              " 1672  5\n",
              " 96    8\n",
              " 1565  2\n",
              " 178   0\n",
              " 108   7\n",
              " 923   8\n",
              " 831   0\n",
              " 1361  5\n",
              " 1537  8\n",
              " 733   4\n",
              " 1     1\n",
              " 997   8\n",
              " 481   6\n",
              " 1311  4\n",
              " 1513  3\n",
              " ...  ..\n",
              " 777   1\n",
              " 72    0\n",
              " 845   9\n",
              " 537   1\n",
              " 1701  6\n",
              " 849   9\n",
              " 1624  3\n",
              " 174   7\n",
              " 87    4\n",
              " 551   5\n",
              " 1510  6\n",
              " 705   3\n",
              " 314   6\n",
              " 1420  5\n",
              " 600   2\n",
              " 1496  7\n",
              " 1094  6\n",
              " 599   3\n",
              " 1778  4\n",
              " 277   1\n",
              " 1747  1\n",
              " 1033  4\n",
              " 1383  8\n",
              " 1731  4\n",
              " 763   5\n",
              " 835   3\n",
              " 1216  3\n",
              " 1653  7\n",
              " 559   7\n",
              " 684   8\n",
              " \n",
              " [1347 rows x 1 columns],\n",
              "       0\n",
              " 1081  2\n",
              " 1707  8\n",
              " 927   2\n",
              " 713   6\n",
              " 262   6\n",
              " 182   7\n",
              " 303   1\n",
              " 895   9\n",
              " 933   8\n",
              " 1266  5\n",
              " 788   2\n",
              " 1410  8\n",
              " 1239  6\n",
              " 6     6\n",
              " 223   6\n",
              " 156   6\n",
              " 1168  1\n",
              " 458   0\n",
              " 1061  5\n",
              " 722   8\n",
              " 513   8\n",
              " 438   7\n",
              " 1015  8\n",
              " 1567  4\n",
              " 1135  7\n",
              " 1320  5\n",
              " 1661  4\n",
              " 934   9\n",
              " 1232  2\n",
              " 971   9\n",
              " ...  ..\n",
              " 726   1\n",
              " 399   3\n",
              " 764   7\n",
              " 1258  0\n",
              " 1516  0\n",
              " 27    7\n",
              " 1663  0\n",
              " 757   4\n",
              " 289   5\n",
              " 1186  9\n",
              " 519   3\n",
              " 1390  3\n",
              " 1254  4\n",
              " 1712  3\n",
              " 210   1\n",
              " 760   8\n",
              " 491   9\n",
              " 1197  8\n",
              " 1758  3\n",
              " 841   6\n",
              " 658   2\n",
              " 667   1\n",
              " 1245  6\n",
              " 2     2\n",
              " 1367  1\n",
              " 1523  7\n",
              " 1044  5\n",
              " 1430  5\n",
              " 1723  1\n",
              " 1262  9\n",
              " \n",
              " [450 rows x 1 columns])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "636tajp8bi65",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# ***4. Use Logistic Regression - ***"
      ]
    },
    {
      "metadata": {
        "id": "oz4V9WtWbnp8",
        "colab_type": "code",
        "outputId": "f61af873-45bd-40c4-d7c2-279959d29445",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier=LogisticRegression()\n",
        "classifier.fit(X_train,Y_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
              "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
              "          tol=0.0001, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "NfThjUy7Od8W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Prediction \n",
        "Y_pred=classifier.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uiUz05PrcNTA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# ***5. Measuring Performance - ***"
      ]
    },
    {
      "metadata": {
        "id": "ASkHTSCGI6zh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**a. Classification Accuracy - **"
      ]
    },
    {
      "metadata": {
        "id": "WGOIkfJWccyh",
        "colab_type": "code",
        "outputId": "154c56e2-2bf1-4d35-b147-c87db907510d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn import metrics \n",
        "metrics.accuracy_score(Y_test,Y_pred)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9533333333333334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "MxJF3sLqhKZ5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**b. Log Loss - **"
      ]
    },
    {
      "metadata": {
        "id": "AIxRzyaQKDFq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "64f0c386-f7b7-4f9d-d979-14f8cc931646"
      },
      "cell_type": "code",
      "source": [
        "print(\"Shape of pred:\",Y_pred.shape)\n",
        "print(\"Shape of Actual:\",Y_test.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of pred: (450,)\n",
            "Shape of Actual: (450, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rDnBBnDaLZse",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y_pred=Y_pred.reshape((450,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jUlNJe-OKV8T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e54c2ca6-67c2-44e9-86f1-ae62185eba34"
      },
      "cell_type": "code",
      "source": [
        "print(\"Shape of pred:\",Y_pred.shape)\n",
        "print(\"Shape of Actual:\",Y_test.shape)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of pred: (450, 1)\n",
            "Shape of Actual: (450, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2je45r6GOk4M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred = classifier.predict_proba(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OTTHdJ8UhOkW",
        "colab_type": "code",
        "outputId": "7e68333f-d280-4441-9918-a6324599ec69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "metrics.log_loss(Y_test,pred)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18820752205570335"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "EzXo5eU8PO43",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Note - **\n",
        "\n",
        "\n",
        "1. Model is good if log loss value is going towards '0'.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "dpGChJvdhVDY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**c. R2 metrics - **"
      ]
    },
    {
      "metadata": {
        "id": "gGVsnt5RhcgR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "R2 squared metrics is applied on regression. But we have classifiaction program. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s4lZ5udZhmEZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**d. Mean Absolute Error - **"
      ]
    },
    {
      "metadata": {
        "id": "8vy1Ced3hrqz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Mean Absolute Error is applied on regression. But we have classifiaction program. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nY7yYeAthxSi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**e. Mean Squared Error - **"
      ]
    },
    {
      "metadata": {
        "id": "SKoG_pE8hxEu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Mean Squared Error is applied on regression. But we have classifiaction program. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZaBTwMf_h4ar",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**f. Confusion Metrics - **"
      ]
    },
    {
      "metadata": {
        "id": "m4tE6dX8iAmv",
        "colab_type": "code",
        "outputId": "afeba83a-68b7-4032-e9ec-4377947b19cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "confusion=metrics.confusion_matrix(Y_test,Y_pred)\n",
        "confusion"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[37,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 0, 39,  0,  0,  0,  0,  2,  0,  2,  0],\n",
              "       [ 0,  0, 41,  3,  0,  0,  0,  0,  0,  0],\n",
              "       [ 0,  0,  1, 43,  0,  0,  0,  0,  0,  1],\n",
              "       [ 0,  0,  0,  0, 38,  0,  0,  0,  0,  0],\n",
              "       [ 0,  1,  0,  0,  0, 47,  0,  0,  0,  0],\n",
              "       [ 0,  0,  0,  0,  0,  0, 52,  0,  0,  0],\n",
              "       [ 0,  1,  0,  1,  1,  0,  0, 45,  0,  0],\n",
              "       [ 0,  3,  1,  0,  0,  0,  0,  0, 43,  1],\n",
              "       [ 0,  0,  0,  1,  0,  1,  0,  0,  1, 44]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "8cCAVCeLiMJ3",
        "colab_type": "code",
        "outputId": "c337203a-7055-4a61-8302-3a4d969a6a9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "cell_type": "code",
      "source": [
        "# plotting heatmap for confusion matrix \n",
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt \n",
        "sns.heatmap(confusion,annot=True,fmt='d')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbwAAAFZCAYAAADjOZruAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "OQz928JVimy7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**g. Classification Report - **"
      ]
    },
    {
      "metadata": {
        "id": "tlfzft_8irry",
        "colab_type": "code",
        "outputId": "58678066-25f5-4a70-a8cc-eedc4c6b3d33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "print(metrics.classification_report(Y_test,Y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        37\n",
            "           1       0.89      0.91      0.90        43\n",
            "           2       0.95      0.93      0.94        44\n",
            "           3       0.90      0.96      0.92        45\n",
            "           4       0.97      1.00      0.99        38\n",
            "           5       0.98      0.98      0.98        48\n",
            "           6       0.96      1.00      0.98        52\n",
            "           7       1.00      0.94      0.97        48\n",
            "           8       0.93      0.90      0.91        48\n",
            "           9       0.96      0.94      0.95        47\n",
            "\n",
            "   micro avg       0.95      0.95      0.95       450\n",
            "   macro avg       0.95      0.95      0.95       450\n",
            "weighted avg       0.95      0.95      0.95       450\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}